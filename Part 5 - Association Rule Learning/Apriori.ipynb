{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Apriori(object):\n",
    "    def __init__(self, itemSets, minSupport=0.5, minConf=0.7, sort = False):\n",
    "        self.itemSets = itemSets\n",
    "        self.minSupport = minSupport\n",
    "        self.minConf = minConf\n",
    "        self.sort = sort\n",
    "        self.__Initialize()\n",
    "\n",
    "    def __Initialize(self):\n",
    "        self.__item()\n",
    "        self.__creat_matrix()\n",
    "        self.update(minSupport=self.minSupport, minConf=self.minConf)\n",
    "\n",
    "    def __item(self):\n",
    "        '''获取项目元素列表'''\n",
    "        self.item = []\n",
    "        for itemSet in self.itemSets:\n",
    "            for item in itemSet:\n",
    "                if item not in self.item:\n",
    "                    self.item.append(item)\n",
    "        self.item.sort()\n",
    "\n",
    "    def __creat_matrix(self):\n",
    "        '''将项集转为pandas.DataFrame数据类型'''\n",
    "        self.data = pd.DataFrame(columns=self.item)\n",
    "        for i in range(len(self.itemSets)):\n",
    "            self.data.loc[i, self.itemSets[i]] = 1\n",
    "\n",
    "    def __candidate_itemsets_l1(self):\n",
    "        '''创建单项频繁项集及L1'''\n",
    "        self.L1 = self.data.loc[:, self.data.sum(axis=0) / len(self.itemSets) >= self.minSupport]\n",
    "        self.L1_support_selects = dict(self.L1.sum(axis=0) / len(self.itemSets))  # 只作为分母，不进行拆分\n",
    "\n",
    "    def __candidate_itemsets_lk(self):\n",
    "        '''根据L1创建多项频繁项集Lk，非频繁项集的任何超集都不是频繁项集'''\n",
    "        last_support_selects = self.L1_support_selects.copy()  # 初始化\n",
    "        while last_support_selects:\n",
    "            new_support_selects = {}\n",
    "            for last_support_select in last_support_selects.keys():\n",
    "                for L1_support_name in set(self.L1.columns) - set(last_support_select.split(',')):\n",
    "                    columns = sorted([L1_support_name] + last_support_select.split(','))  # 新的列名：合并后排序\n",
    "                    count = (self.L1.loc[:, columns].sum(axis=1) == len(columns)).sum()\n",
    "                    if count / len(self.itemSets) >= self.minSupport:\n",
    "                        new_support_selects[','.join(columns)] = count / len(self.itemSets)\n",
    "            self.support_selects.update(new_support_selects)\n",
    "            last_support_selects = new_support_selects.copy()  # 作为新的 Lk，进行下一轮更新\n",
    "\n",
    "    def __support_selects(self):\n",
    "        '''支持度选择'''\n",
    "        self.__candidate_itemsets_l1()\n",
    "        self.__candidate_itemsets_lk()\n",
    "        self.item_Conf = self.L1_support_selects.copy()\n",
    "        self.item_Conf.update(self.support_selects)\n",
    "\n",
    "    def __confidence_selects(self):\n",
    "        '''生成关联规则，其中support_selects已经按照长度大小排列'''\n",
    "        for groups, Supp_groups in self.support_selects.items():\n",
    "            groups_list = groups.split(',')\n",
    "            for recommend_len in range(1, len(groups_list)):\n",
    "                for recommend in itertools.combinations(groups_list, recommend_len):\n",
    "                    items = ','.join(sorted(set(groups_list) - set(recommend)))\n",
    "                    Conf = Supp_groups / self.item_Conf[items]\n",
    "                    if Conf >= self.minConf:\n",
    "                        self.confidence_select.setdefault(items, {})\n",
    "                        self.confidence_select[items].setdefault(','.join(recommend),{'Support': Supp_groups, 'Confidence': Conf})\n",
    "\n",
    "    def show(self,**kwargs):\n",
    "        '''可视化输出'''\n",
    "        if kwargs.get('data'):\n",
    "            select = kwargs['data']\n",
    "        else:\n",
    "            select = self.confidence_select\n",
    "        items = []\n",
    "        value = []\n",
    "        for ks, vs in select.items():\n",
    "            items.extend(list(zip([ks] * vs.__len__(), vs.keys())))\n",
    "            for v in vs.values():\n",
    "                value.append([v['Support'], v['Confidence']])\n",
    "        index = pd.MultiIndex.from_tuples(items, names=['Items', 'Recommend'])\n",
    "        self.rules = pd.DataFrame(value, index=index, columns=['Support', 'Confidence'])\n",
    "        if self.sort or kwargs.get('sort'):\n",
    "            result = self.rules.sort_values(by=['Support', 'Confidence'], ascending=False)\n",
    "        else:\n",
    "            result = self.rules.copy()\n",
    "        return result\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        '''用于更新数据'''\n",
    "        if kwargs.get('minSupport'):\n",
    "            self.minSupport = kwargs['minSupport']\n",
    "            self.support_selects = {}  # 用于储存满足支持度的频繁项集\n",
    "            self.__support_selects()\n",
    "        if kwargs.get('minConf'):\n",
    "            self.minConf = kwargs['minConf']\n",
    "            self.confidence_select = {}  # 用于储存满足自信度的关联规则\n",
    "            self.__confidence_selects()\n",
    "        print(self.show())\n",
    "        if kwargs.get('file_name'):\n",
    "            file_name = kwargs['file_name']\n",
    "            self.show().to_excel(f'/../table/{file_name}.xlsx')\n",
    "        self.apriori_rules = self.rules.copy()\n",
    "\n",
    "    def __get_Recommend_list(self,itemSet):\n",
    "        '''输入数据，获取关联规则列表'''\n",
    "        self.recommend_selects = {}\n",
    "        itemSet = set(itemSet) & set(self.apriori_rules.index.levels[0])\n",
    "        if itemSet:\n",
    "            for start_str in itemSet:\n",
    "                for end_str in self.apriori_rules.loc[start_str].index:\n",
    "                    start_list = start_str.split(',')\n",
    "                    end_list = end_str.split(',')\n",
    "                    self.__creat_Recommend_list(start_list, end_list, itemSet)\n",
    "\n",
    "    def __creat_Recommend_list(self,start_list,end_list,itemSet):\n",
    "        '''迭代创建关联规则列表'''\n",
    "        if set(end_list).issubset(itemSet):\n",
    "            start_str = ','.join(sorted(start_list+end_list))\n",
    "            if start_str in self.apriori_rules.index.levels[0]:\n",
    "                for end_str in self.apriori_rules.loc[start_str].index:\n",
    "                    start_list = start_str.split(',')\n",
    "                    end_list = end_str.split(',')\n",
    "                    self.__creat_Recommend_list(sorted(start_list),end_list,itemSet)\n",
    "        elif not set(end_list) & itemSet:\n",
    "            start_str = ','.join(start_list)\n",
    "            end_str = ','.join(end_list)\n",
    "            self.recommend_selects.setdefault(start_str, {})\n",
    "            self.recommend_selects[start_str].setdefault(end_str, {'Support': self.apriori_rules.loc[(start_str, end_str), 'Support'], 'Confidence': self.apriori_rules.loc[(start_str, end_str), 'Confidence']})\n",
    "\n",
    "    def get_Recommend(self,itemSet,**kwargs):\n",
    "        '''获取加权关联规则'''\n",
    "        self.recommend = {}\n",
    "        self.__get_Recommend_list(itemSet)\n",
    "        self.show(data = self.recommend_selects)\n",
    "        items = self.rules.index.levels[0]\n",
    "        for item_str in items:\n",
    "            for recommends_str in self.rules.loc[item_str].index:\n",
    "                recommends_list = recommends_str.split(',')\n",
    "                for recommend_str in recommends_list:\n",
    "                    self.recommend.setdefault(recommend_str,0)\n",
    "                    self.recommend[recommend_str] += self.rules.loc[(item_str,recommends_str),'Support'] * self.rules.loc[(item_str,recommends_str),'Confidence'] * self.rules.loc[item_str,'Support'].mean()/(self.rules.loc[item_str,'Support'].sum()*len(recommends_list))\n",
    "        result = pd.Series(self.recommend,name='Weight').sort_values(ascending=False)\n",
    "        result.index.name = 'Recommend'\n",
    "        result = result/result.sum()\n",
    "        result = 1/(1+np.exp(-result))\n",
    "        print(result)\n",
    "        if kwargs.get('file_name'):\n",
    "            file_name = kwargs['file_name']\n",
    "            excel_writer = pd.ExcelWriter(f'{os.getcwd()}/../table/{file_name}.xlsx')\n",
    "            result.to_excel(excel_writer,'推荐项目及权重')\n",
    "            self.rules.to_excel(excel_writer, '关联规则树状表')\n",
    "            self.show().to_excel(excel_writer, '总关联规则树状表')\n",
    "            self.show(sort = True).to_excel(excel_writer, '总关联规则排序表')\n",
    "            excel_writer.save()\n",
    "        return result\n",
    "\n",
    "def str2itemsets(strings, split=','):\n",
    "    '''将字符串列表转化为对应的集合'''\n",
    "    itemsets = []\n",
    "    for string in strings:\n",
    "        itemsets.append(sorted(string.split(split)))\n",
    "    return itemsets\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1.导入数据\n",
    "    data = pd.read_excel(r'apriori算法实现.xlsx', index=False)\n",
    "\n",
    "    # 2.关联规则中不考虑多次购买同一件物品，删除重复数据\n",
    "    data = data.drop_duplicates()\n",
    "\n",
    "    # 3.初始化列表\n",
    "    itemSets = []\n",
    "\n",
    "    # 3.按销售单分组，只有1件商品的没有意义，需要进行过滤\n",
    "    groups = data.groupby(by='销售单明细')\n",
    "    for group in groups:\n",
    "        if len(group[1]) >= 2:\n",
    "            itemSets.append(group[1]['商品编码'].tolist())\n",
    "\n",
    "    # 4.训练 Apriori\n",
    "    ap = Apriori(itemSets, minSupport=0.03, minConf=0.5)\n",
    "    ap.get_Recommend('2BYP206,2BYW001-,2BYW013,2BYX029'.split(','))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
