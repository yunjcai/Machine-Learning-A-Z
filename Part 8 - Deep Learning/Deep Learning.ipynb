{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning models can be used for a variety of complex tasks:\n",
    "* Artificial Neural Networks for Regression and Classification\n",
    "* Convolutional Neural Networks for Computer Vision\n",
    "* Recurrent Neural Networks for Time Series Analysis\n",
    "* Self Organizing Maps for Feature Extraction\n",
    "* Deep Boltzmann Machines for Recommendation Systems\n",
    "* Auto Encoders for Recommendation Systems\n",
    "\n",
    "We create an artificial structure called an artificial neural net (nodes or neurons). We will have some neurons for input values which are processed through all hidden layers just like in the human brain to have an output value. It is the Deep Learning.<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_1.JPG?raw=true' width='600'>\n",
    "\n",
    "##### 参考：\n",
    "[神经网络入门](http://www.ruanyifeng.com/blog/2017/07/neural-network.html#support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neuron is the basic building block of Artificial Neural Networks.<br>\n",
    "\n",
    "All input values can be considered as independent variable, and those will be added up or multiplied by some weight. In the case, they will be easier for neural network to process them if they are all about the same (Standardize or Normalize)<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_2.JPG?raw=true' width='500'><br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_3.JPG?raw=true' width='500'><br>\n",
    "If the output is categorical, then it will be several outputs values ($y_1, y_2 ... y_n$) because these will be dummy variables which will be representing the categories.\n",
    "\n",
    "The inputs are single observation (only in one row in the dataset) and the output is single observation as well. It means the input is for one row in dataset, then the output is for that the same exact row.<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_4.JPG?raw=true' width='500'><br>\n",
    "It's just all values in one row with different characteristics or attributes(columns) relating to that one observation(row), every single time, we are dealing with.\n",
    "\n",
    "All the Synapse get assigned weights. By adjusting the weights, the neural network decides in every single case (which signal is not important). It means we are training the artificial neural network by adjusting all of the weights in all of the synapse across the whole neural network.<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_5.JPG?raw=true' width='500'><br>\n",
    "\n",
    "Here is the thing happened in Neural node:<br>\n",
    "STEP 1: To sum up all inputs with their weights<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_6.JPG?raw=true' width='500'><br>\n",
    "STEP 2: Apply the activation function which is assigned to the current neuron (or to the whole layer). <br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_7.JPG?raw=true' width='500'><br>\n",
    "STEP 3: The neuron will decide whether pass the signal or not based on the activation function applied in STEP 2.<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_8.JPG?raw=true' width='500'><br>\n",
    "Finally, those STEPs will be repeated throughout the whole neural network on and on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold Function (Yes or No type function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_9.JPG?raw=true' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function is useful in the final layer output. Especially when we are trying to predict probabilities. The probability of y is equal to 1.<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_10.JPG?raw=true' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectifier Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectifier function is one of the most popular functions in Artificial Neural Network.<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_11.JPG?raw=true' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperbolic Tangent (tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_12.JPG?raw=true' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which activation function we should use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_24.JPG?raw=true' width='500'><br>\n",
    "When the Dependent Variable (y) is binary (y = 0 or 1):<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_13.JPG?raw=true' width='500'><br>\n",
    "\n",
    "We also can apply the rectifier function in the hidden layers and the sigmoid function in the output layers<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_14.JPG?raw=true' width='500'><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do Neural Networks Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个 Neural node (hidden layer) 根据自身的特点方面，可以 take 不同的 input values，以及不同的 activation function，最后合并产生结果。\n",
    "\n",
    "The whole hidden layers allows to increase the flexibility of the neural network. It allows the neural network to look for very specific things and then in combination.<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_15.JPG?raw=true' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do Neural Networks Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对结果的对比，让 Neural Networks 自己摸索学习。\n",
    "\n",
    "使用 cost function: $C = \\frac{(\\hat{y} - y)^2}{2}$，比较预测值和真实值的区别，并反馈给 Neural Networks。Neural Networks 将调解 weights 值，来缩小 cost function。<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_16.JPG?raw=true' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当 multiple rows inputs into the same ONE neural networks (not 8 neural network, just the same one)，产生相对应 each row 的$\\hat{y}$<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_17.JPG?raw=true' width='500'><br>\n",
    "随后比较相对应 each row 的真实值($y$)，生成$C= \\sum \\frac{(\\hat{y} - y)^2}{2}$。使用新生成的 Cost function (C) 来调节当前 neural network 中的 $w_1, w_2, w_3$ (the weights are the same for all of the rows, all the rows share the same weights)，最终使 Cost function 最小化。<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_18.JPG?raw=true' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 中所有 rows 全部输入同一 neural network 中，得到 Cost function。<br><img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_20.JPG?raw=true' width='400'>\n",
    "\n",
    "通过对 Cost funtion 求导得到斜率，'-'为 downhill 则需要调整 weights，使$\\hat{y}$向右趋近取值； '+'为 uphill 则需要调整 weights，使$\\hat{y}$向左趋近取值。直至斜率 = 0 得到最小 Cost function (可能是 local minimum)<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_19.JPG?raw=true' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Gradient Descent:** Adjust weights after runing all of the rows in the same neural network. Then adjust weights and run the whole thing again (iteration) until minimize the Cost function.\n",
    "\n",
    "**Stochastic Gradient Descent:** Run one row at a time, then adjust weights (iteration) till minimize the Cost function. Then run next single row into the same neural network...<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_21.JPG?raw=true' width='400'>\n",
    "\n",
    "The stochastic gradient helps to avoid local minimums issue and it's faster than the batch gradient.\n",
    "\n",
    "**Mini Batch Gradient Descent:** combine both batch and stochastic gradient. Run 5, 10 or 100 rows (set by users) at a time, then adjust weights like stochastic gradient.\n",
    "\n",
    "##### 参考：\n",
    "[A Neural Network in 13 lines of Python (Part 2 - Gradient Descent)](https://iamtrask.github.io/2015/07/27/python-network-part2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information is entered into the input layer and then it's propagated forward to get the output values $\\hat{y}$. Then we compare $\\hat{y}$ to the actual values that we have in the training set. Then we calculate the errors (cost function).<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_22.JPG?raw=true' width='400'><br>\n",
    "Then feedback the errors (back propagate) through the network in the opposite direction and **it allows us to train the network by adjusting ALL the weights AT THE SAME TIME.**<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_23.JPG?raw=true' width='400'><br>\n",
    "The advantage of back propagation is the way algorithm to be structured. So you know which part of the error each weights in the neural network is repsonsible for.\n",
    "\n",
    "##### 参考：\n",
    "[Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap2.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the ANN with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 1:** Randomly initialise the weights to small numbers close to 0 (but not 0).<br>\n",
    "**STEP 2:** Input the first observation (first row) of the dataset in the input layer, each feature in one input node. (basically take the columns and put them into the input nodes)<br>\n",
    "**STEP 3:** Forward Propagation - from left to right, the neurons are activated in a way that the impact of each neuron's activation is limited by the weights (the weights determine how important each neurons activation is). Propagate the activations until getting the predicted result $y$<br>\n",
    "**STEP 4:** Compare the predicted result to the actual result. Measure the generated error (Cost function)<br>\n",
    "**STEP 5:** Back Propagation - from right to left, the error is back-propagated. Update the weights according to how much they are responsible for the error (because of the way back-propagated algorithm is structured). The learning rate decides by how much we update the weights.<br>\n",
    "**STEP 6:** Repeat STEPs 1-5 and update the weights after each observation (Reinforcement Learning, in our case, it is Stochastic Gradient Descent). Or: Repeat STEPs 1-5 but udpate the weights only after a batch of observation (Batch Learning).<br>\n",
    "**STEP 7:** When the whole training set passed through the ANN, that makes an epoch. Redo more epochs. (basically just keep doing again and again, to train better and better and adjust itself until the cost function is minimum.)\n",
    "\n",
    "epoch defines the number times that the learning algorithm will work through the entire training dataset. One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches. For example, as above an epoch that has one batch is called the batch gradient descent learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variables: CreditScore,Geography,Gender,Age,\n",
    "# Tenure,Balance,NumOfProducts,HasCrCard,IsActiveMember,EstimatedSalary\n",
    "# ANN will determine which independent variable will be more important.\n",
    "X = dataset.iloc[:,3:13].values\n",
    "y = dataset.loc[:,'Exited'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some Categorical variables in our matrix of features. Therefore, we need to encode them (OneHotEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Encodes any categorical data in the dataset\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# In the dataset, only 'Geography' and 'Gender' need to be encoded.\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:,1] = labelencoder_X_1.fit_transform(X[:,1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:,2] = labelencoder_X_2.fit_transform(X[:,2])\n",
    "\n",
    "# The categorical variables are NOT ordinal \n",
    "# (No relational order between the categorical variables)\n",
    "# For example, France (2) is NOT higher than Germany (1)\n",
    "# So we need create dummy variables for these categorical variables\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "# In order to convert X to be a matrix, we need add '.toarray()' in the end.\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "# To remove one dummy variable in order to avoid falling into the dummy variable trap.\n",
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**We need apply feature scaling on the ALL general deep learning (ANN and CNN)**</font><br>\n",
    "\n",
    "Because there will be a lot of highly compute intensive calculations and besides parallel computations<br>\n",
    "We need apply feature scaling to ease of these calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "sc = ss()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Artificial Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and package\n",
    "import keras  # keras will build neural networks based on TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need import two modules here:\n",
    "* The sequential module - it is required to initialize the neural network\n",
    "* The dense module - it is required to build the layers of ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialising the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need add any arguments, \n",
    "# because we will define the layers step by step\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding the input layer and the 1st hidden layer\n",
    "**使用 .add(Dense function)来建立或者添加每一层layer.**<br>\n",
    "\n",
    "Dense function 的 arguments:\n",
    "* units: 此次建模的 output nodes number。因为是第一层 hidden layer，所以 output nodes number 就是 hidden layer nodes number.\n",
    "* kernel_initializer: use a uniform function to initialize the weights (STEP 1)\n",
    "* activation: the activation function will be chosen in the hidden layer (best option - Rectifier Function)\n",
    "* input_dim: the number of nodes in the input layer, which is also the number of independent variables <br>\n",
    "\n",
    "注意：第一次定义 Dense function 时，因为所有 layer 还未生成，第一层的 hidden layer 没有任何关于 input layer 的信息。所以必须注明 input layer node 数量。hidden layer 建立后，再添加 hidden layer 就无需特别定义了\n",
    "\n",
    "**To choose the number of nodes in the hidden layer as the average of the number of nodes in the input layer and the number of nodes in the output layer**\n",
    "* $Nodes_{hidden} = \\frac{Nodes_{input} + Nodes_{output}}{2}$\n",
    "\n",
    "The best option for the activation function is **Rectifier Function** (based on experiments & research)<br>\n",
    "The 2nd option is **Sigmoid Function**, it will allow us to get the probabilities of the different segments.<br>\n",
    "注意：Sigmoid Function is only for single output layer. We will use soft_max function if the output layer has 2 or more categories<br>\n",
    "\n",
    "Hidden Layer : Rectifier Function; Output Layer: Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Apps\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding the second hidden layer\n",
    "因为 layer 已经建立了，所以不需要特别注明 input_dim 了。<br>\n",
    "第二层 hidden layer 可以选择其他 activation function，但是因为 Rectifier Function 是最好选择，所以仍然选择它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding the output layer\n",
    "now the output layer node is only 1 node, so units = 1<br>\n",
    "We need know the probability about customer leave or stay in the bank, <br>\n",
    "so use sigmoid function as activation function<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compiling the ANN\n",
    "'Compile' means We apply the Stochastic Gradient Descent on the whole ANN<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_26.JPG?raw=true' width='600'><br>\n",
    "* optimizer: the algorithm we want to use to find the optimal set of weights in the neural networks (there're several Stochastic Gradient algorithm, the best one is called 'adam')\n",
    "* loss: this corresponds to the lost function. The loss function is kind of the same as for logistic regression.<br><img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_27.JPG?raw=true' width='600'>\n",
    "* metrics: a criterion we will choose to evaluate the model (typically we use the 'accuracy' criterion). This arugment must be a list.\n",
    "\n",
    "注：since the activation function for the output layer is the sigmoid function and we use adam stochastic gradient algorithm. So we will use 'Logarithmic Loss' as well. <br>\n",
    "* if the dependent variable has a binary outcome then the logarithmic loss function is called <b>binary_crossentropy</b>.\n",
    "* if the dependent variable has more than 2 outcomes like three categories, then the logarithmic function is called <b>categorical_crossentropy</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting the ANN to the Training set\n",
    "Two new arguments in .fit function:\n",
    "* batch_size: In STEP 6, we can choose to update the weights either after each observation/row (Reinforcement Learning)  or after a batch of observations (Batch Learning). Therefore, we need select batch sizewhich is the number of observations after which we want to update the weights\n",
    "* epochs: number of epoch. In STEP 7, the epoch is basically around when the whole training set passed through the ANN. In reality training of ANN consists of applying STEPs 1-6 over many epochs\n",
    "\n",
    "epoch defines the number times that the learning algorithm will work through the entire training dataset. One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches. For example, as above an epoch that has one batch is called the batch gradient descent learning algorithm.\n",
    "\n",
    "注意：选择 batch_size 和 nb_epoch 没有技巧，只能靠实验。<br>\n",
    "\n",
    "经过 training, Accuracy 会随着回合慢慢增长。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Apps\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 0.4909 - acc: 0.7952\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 0.4288 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 0.4219 - acc: 0.8060\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 0.4156 - acc: 0.8257\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 0.4114 - acc: 0.8307\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 0.4081 - acc: 0.8341\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 0.4058 - acc: 0.8342\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4039 - acc: 0.8339\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.4025 - acc: 0.8332\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.4011 - acc: 0.8360\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.4004 - acc: 0.8341\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3999 - acc: 0.8341\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3989 - acc: 0.8346\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3987 - acc: 0.8347\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3977 - acc: 0.8355\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3972 - acc: 0.8335\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3965 - acc: 0.8345\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3962 - acc: 0.8354\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.3957 - acc: 0.8336\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.3946 - acc: 0.8385\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.3935 - acc: 0.8376\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.3927 - acc: 0.8389\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3908 - acc: 0.8389\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3875 - acc: 0.8366\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3874 - acc: 0.8402\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3843 - acc: 0.8357\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3809 - acc: 0.8404\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3782 - acc: 0.8401\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3760 - acc: 0.8406\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.3729 - acc: 0.8437\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.3692 - acc: 0.8454\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.3666 - acc: 0.8480\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.3648 - acc: 0.8489\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.3619 - acc: 0.8516\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.3595 - acc: 0.8535\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.3576 - acc: 0.8547\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.3555 - acc: 0.8526\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.3538 - acc: 0.8535\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.3535 - acc: 0.8541\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.3526 - acc: 0.8556\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.3516 - acc: 0.8552\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.3510 - acc: 0.8571\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.3502 - acc: 0.8561\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.3493 - acc: 0.8570\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.3485 - acc: 0.8557\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.3478 - acc: 0.8579\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3470 - acc: 0.8581\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3472 - acc: 0.8596\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3471 - acc: 0.8570\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3464 - acc: 0.8570\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3458 - acc: 0.8612\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3450 - acc: 0.8596\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3441 - acc: 0.8599\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3456 - acc: 0.8575\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3437 - acc: 0.8627\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3436 - acc: 0.8581\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3432 - acc: 0.8595\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3442 - acc: 0.8601\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3439 - acc: 0.8604\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3435 - acc: 0.8582\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3434 - acc: 0.8610\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3435 - acc: 0.8620\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3427 - acc: 0.8597\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3434 - acc: 0.8607\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3440 - acc: 0.8596\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3428 - acc: 0.8580\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3419 - acc: 0.8596\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3429 - acc: 0.8611\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.3429 - acc: 0.8594\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.3430 - acc: 0.8597\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.3426 - acc: 0.8592\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.3420 - acc: 0.8597\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3420 - acc: 0.8599\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3432 - acc: 0.8602\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3419 - acc: 0.8616\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3426 - acc: 0.8609\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.3429 - acc: 0.8591\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.3420 - acc: 0.8610\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.3419 - acc: 0.8610\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.3425 - acc: 0.8594\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3423 - acc: 0.8606\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.3415 - acc: 0.8612\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.3410 - acc: 0.8612\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3411 - acc: 0.8614\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.3415 - acc: 0.8599\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3419 - acc: 0.8589\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3417 - acc: 0.8610\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3416 - acc: 0.8602\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3411 - acc: 0.8616\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3414 - acc: 0.8602\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3421 - acc: 0.8586\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3408 - acc: 0.8622\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3413 - acc: 0.8580\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.3413 - acc: 0.8615\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.3419 - acc: 0.8614\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3406 - acc: 0.8601\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3415 - acc: 0.8602\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3405 - acc: 0.8600\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3421 - acc: 0.8587\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3405 - acc: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d95595c630>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the Predictions and Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting the Test set results\n",
    "The .predict method returns the probability<br>\n",
    "Since our predict result is the probability. We need the threshold to convert probability to 1/0<br>\n",
    "So we choose 50% as threshold here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1544,   51],\n",
       "       [ 224,  181]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      1595\n",
      "           1       0.78      0.45      0.57       405\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.83      0.71      0.74      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are convolutional neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 参考：\n",
    "[一文看懂卷积神经网络](https://easyai.tech/ai-definition/cnn/)\n",
    "\n",
    "卷积神经网络(Convolutional Neural Network, CNN)最擅长的就是图片的处理。它受到人类视觉神经系统的启发。\n",
    "\n",
    "CNN 有2大特点：\n",
    "1. 能够有效的将大数据量的图片降维成小数据量\n",
    "2. 能够有效的保留图片特征，符合图片处理的原则\n",
    "\n",
    "目前 CNN 已经得到了广泛的应用，比如：人脸识别、自动驾驶、美图秀秀、安防等很多领域。\n",
    "\n",
    "#### CNN 解决了什么问题？\n",
    "在 CNN 出现之前，图像对于人工智能来说是一个难题，有2个原因：\n",
    "1. 图像需要处理的数据量太大，导致成本很高，效率很低\n",
    "2. 图像在数字化的过程中很难保留原有的特征，导致图像处理的准确率不高\n",
    "\n",
    "下面就详细说明一下这2个问题：<br>\n",
    "\n",
    "**需要处理的数据量太大**<br>\n",
    "图像是由像素构成的，每个像素又是由颜色构成的。现在随随便便一张图片都是 $1000×1000$ 像素以上的， 每个像素都有RGB 3个参数来表示颜色信息。假如我们处理一张 $1000×1000$ 像素的图片，我们就需要处理3百万个参数！$1000×1000×3=3,000,000$\n",
    "\n",
    "**卷积神经网络 – CNN 解决的第一个问题就是「将复杂问题简化」，把大量参数降维成少量参数，再做处理。**<br>\n",
    "更重要的是：我们在大部分场景下，降维并不会影响结果。比如1000像素的图片缩小成200像素，并不影响肉眼认出来图片中是一只猫还是一只狗，机器也是如此。\n",
    "\n",
    "**保留图像特征**<br>\n",
    "图片数字化的传统方式我们简化一下，就类似下图的过程：<br><img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/a401a747520e93cdcbd80ef3cf5c8ac6a120ee03/Part%208%20-%20Deep%20Learning/dl_28.JPG?raw=true' width='500'><br>\n",
    "假如有圆形是1，没有圆形是0，那么圆形的位置不同就会产生完全不同的数据表达。但是从视觉的角度来看，**图像的内容（本质）并没有发生变化，只是位置发生了变化。**\n",
    "\n",
    "所以当我们移动图像中的物体，用传统的方式的得出来的参数会差异很大！这是不符合图像处理的要求的。\n",
    "\n",
    "**而 CNN 解决了这个问题，他用类似视觉的方式保留了图像的特征，当图像做翻转，旋转或者变换位置时，它也能有效的识别出来是类似的图像。**\n",
    "\n",
    "#### 人类的视觉原理\n",
    "人类的视觉原理如下：从原始信号摄入开始（瞳孔摄入像素 Pixels），接着做初步处理（大脑皮层某些细胞发现边缘和方向），然后抽象（大脑判定，眼前的物体的形状，是圆形的），然后进一步抽象（大脑进一步判定该物体是只气球）。下面是人脑进行人脸识别的一个示例：<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_30.JPG?raw=true' width='400'><br>\n",
    "我们可以看到，在最底层特征基本上是类似的，就是各种边缘，越往上，越能提取出此类物体的一些特征（轮子、眼睛、躯干等），到最上层，不同的高级特征最终组合成相应的图像，从而能够让人类准确的区分不同的物体。\n",
    "\n",
    "那么我们可以很自然的想到：可以不可以模仿人类大脑的这个特点，构造多层的神经网络，较低层的识别初级的图像特征，若干底层特征组成更上一层特征，最终通过多个层级的组合，最终在顶层做出分类呢？\n",
    "\n",
    "这也是许多深度学习算法（包括CNN）的灵感来源。\n",
    "\n",
    "#### 典型的 CNN 由3个部分构成：\n",
    "\n",
    "* 卷积层：负责提取图像中的局部特征\n",
    "* 池化层：用来大幅降低参数量级(降维)\n",
    "* 全连接层：类似传统神经网络的部分，用来输出想要的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Convolution Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Convolution:</b> 一个 function 通过另一个 function 时，产生的变化。<br> $(f*g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau)g(t-\\tau) \\; d\\tau$\n",
    "\n",
    "卷积层的运算过程如下图，用一个 feature detector/kernel/filter - 卷积核/过滤器） 扫完整张图片：<br>\n",
    "$I_{00}$ x $C_{00}$ + $I_{01}$ x $C_{01}$ + $I_{02}$ x $C_{02}$ + $I_{03}$ x $C_{03}$ + $I_{10}$ x $C_{10}$ + ...<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/2019-06-19-juanji.gif?raw=true' width='300'><br>\n",
    "这个过程我们可以理解为: 使用过滤器(一种图形模式，已知特征)来过滤图像的各个小区域，从而得到这些小区域的特征值。最后生成包含所有特征值的矩阵 - Feature Map (上图中为 Convolved Feature). **如果 Feature Map 中特征值越大，则认为此图像块和所用的过滤器(已知特征)越接近。**对照已知特征，从而辨别出图像是什么。\n",
    "\n",
    "以上动图中，Stride(步长)为1，即每次过滤器只向右移动1格。步长可以为2(向右移动2格)。当移到下一行时，同样要下移2行而非1行。卷积后，feature map 变得更小(步长越大，feature map 越小)，这样处理起来更容易更快。\n",
    "\n",
    "如果步长使过滤器超出原图范围，则无视超出范围，仅使用过滤器范围内的剩余数值计算。<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_32.JPG?raw=true' width='150'>\n",
    "\n",
    "在具体应用中，往往有多个卷积核，如果我们设计了n个卷积核，可以生成n个 feature maps，这n个 feature maps 组成 first convolution layer (卷积层)。通过 training, network can decide which feature is more important. 可以理解为这个图像上有n种底层纹理模式，也就是用n种基础模式就能描绘出一副图像。以下就是25种不同的卷积核的示例：<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/2019-06-19-150926.jpg?raw=true' width='100'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1(b) - ReLU Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_31.JPG?raw=true' width='400'><br>\n",
    "在建立 convolutional layer 后，使用 Rectifir Function. 目的是增加 network 的 non-linearity。因为 image 是 highly non-linear 的，但当我们 apply some math operation such as convolution and running the feature detection to create the feature maps，有一定几率产生了 linearity。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "池化层（下采样）—— 数据降维，避免过拟合<br>\n",
    "池化层简单说就是下采样，他可以大大降低数据的维度。其过程如下：<br><img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/2019-06-19-chihua.gif?raw=true' width='400'><br>\n",
    "上图中，我们可以看到，原始图片是$20×20$的，我们对其进行下采样，采样窗口为$10×10$，最终将其下采样成为一个$2×2$大小的特征图。<br>\n",
    "\n",
    "同 convolution 一样，可以自由选择步长(Stride)。如果步长使过滤器超出原图范围，则无视超出范围，仅使用过滤器范围内的剩余数值计算。<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_32.JPG?raw=true' width='150'>\n",
    "\n",
    "之所以这么做的原因，是因为即使做完了卷积，图像仍然很大（因为卷积核比较小），所以为了降低数据维度，就进行下采样。\n",
    "\n",
    "**池化层相比卷积层可以更有效的降低数据维度，这么做不但可以大大减少运算量，还可以有效的避免过拟合(overfitting)。**\n",
    "\n",
    "当图片或近或远，挤压或拉大，正面侧面不同时。我们的 neural network 需要一定等级的 flexibility to be able to still find the features. <br>\n",
    "Pooling 在有效降维的同时，使 neural network 保持对图片的辨识度。\n",
    "\n",
    "Pooling 有很多种：\n",
    "* Max Pooling - 取采样窗口中的最大值\n",
    "* Average Pooling (subsampling) - 取采样窗口中的平均值\n",
    "\n",
    "例如，下图中假设'4'为鼻子。Max Pooling 后，哪怕鼻子位置改变，但是采样窗仍然采集到鼻子的信息('4')。<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_33.JPG?raw=true' width='400'>\n",
    "\n",
    "通过 Pooling 后，建立起 Pooling Layer<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_34.JPG?raw=true' width='400'><br>\n",
    "##### 参考：\n",
    "[Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition](http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将得到的影像矩阵 (Pooled Feature Map) 转换成 one vector. <br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_35.JPG?raw=true' width='300'><br>\n",
    "如果是多个 Pooled Feature Maps 组成的 Pooling Layer, 则同样把每个 Pooled Feature Map 转成 one vector，最后连在一起，组成 one huge vector.<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_36.JPG?raw=true' width='300'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全连接层 —— 同 Artificial Neural Network 相似，只是 hidden layer，又称 Full Connection Layer。最终输出预测结果<br>\n",
    "经过卷积层和池化层降维过的数据输入到全连接层，得到预测结果，计算 loss function 偏差，然后 back propagate，在 Artificial Neural Network 中 adjust weights，同时需要 adjust Feature Detectors (检测是否选择错误 Feature)。然后重复 forward/back propagate<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_37.JPG?raw=true' width='400'><br>\n",
    "在训练过程中，预测结果不断和真实结果比较，同时确定哪些 neural nodes (值为0-1) “属于”自己。如下图，在不断训练中，当紫线 nodes 出现高值(如 0.9)，模型发现 'Dog' 是正确结果，于是这些 nodes 将赋予高 weights 给 'Dog'。同理，训练后，模型发现绿色 nodes 出现高值时，更多显示是 'Cat' 结果，于是绿色 nodes 上将被赋予选择 'Cat' 的高 weights。<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_39.JPG?raw=true' width='400'><br>\n",
    "典型的 CNN 并非只是上面提到的3层结构，而是多层结构，例如 LeNet-5 的结构就如下图所示：<br>\n",
    "卷积层 – 池化层- 卷积层 – 池化层 – 卷积层 – 全连接层<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/2019-06-19-lenet.png?raw=true' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_40.JPG?raw=true' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax & Cross-Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Entropy 只针对 Classification。如果是 Regression 等，还是使用 Mean Squared Error (MSE)。\n",
    "\n",
    "最初得到的 Dog/Cat 值相加并非为1。可以是一大一小任意值。然后 Apply SoftMax function 得到相加为1的两个值。<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_41.JPG?raw=true' width='400'><br>\n",
    "Cross-Entropy Function: $L_i = -log(\\frac{e^{f_{y_i}}}{\\sum_je^{f_j}}) \\rightarrow H(p,q) = - \\sum_xp(x)log(q(x))$<br>\n",
    "在使用完 SoftMax function 后，使用 Cross-Entropy 来 minimize errors and maximize the optimional. 下图中，分别将得出 Dog 的概率和 Dog 的确定值(1为狗，0为猫)，代入 Cross-Entropy。<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_42.JPG?raw=true' width='400'>\n",
    "\n",
    "##### 为何更倾向于用 Cross-Entropy而非MSE\n",
    "Cross-Entropy 更加的敏感和精准的察觉 Neural Network 在调整后的进步值。在最开始阶段，信息非常少，error可能非常小的情况下，如$10^{-6} \\rightarrow 10^{-3}$，MSE 可能不觉得有很大的进步。但是Cross-Entropy 中的$log$可以显示神经网有了巨大的进步。因为其他算法错误的以为进步值太小，所以they won't guide the back propagation in the right direction.\n",
    "\n",
    "##### 参考：\n",
    "[A Friendly Introduction to Cross-Entropy Loss](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 keras 来导入图片数据。所以需要手动建立 folders - train_set, test_set。并且在 train/test folder 中建立分类的子文件夹(如 dogs, cats)。<br>\n",
    "因此不需要像常规步骤那样，做 data preprocessing, train_test_split(已手动完成分类)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "\n",
    "# The Sequential package will initialize the neural network\n",
    "# 2 ways of initializing a neural network either as a sequence of layers\n",
    "# or as a graph (CNN is still a sequence of layers)\n",
    "from keras.models import Sequential\n",
    "\n",
    "# since we work on images which are in 2D (video is 3D with time)\n",
    "\n",
    "# The convolution step to add convolution layer\n",
    "from keras.layers import Conv2D\n",
    "# To process the pooling step and add the pooling layers\n",
    "from keras.layers import MaxPooling2D\n",
    "# Convert all the pooled feature maps into the large feature vector\n",
    "# which becomes the input of the fully connected layers.\n",
    "from keras.layers import Flatten\n",
    "# To add the fully connected layers and the artificial neural network\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialising the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 1:** Convolution\n",
    "\n",
    "注：Dense function 用来添加最后阶段的 fully connected layer，如 ANN。所以这里不用 Dense function 来建立 convolutional layer。\n",
    "\n",
    "Conv2D 的 arguments:\n",
    "* nb_filter: the number of feature detectors we will use.(将会产生数量相同的 feature maps)\n",
    "* nb_row: the number of rows of the feature detector\n",
    "* nb_col: the number of columns of the feature detector\n",
    "* border_mode: how the feature detectors will handle the borders of the input image (use default 'same')\n",
    "* input_shape: the shape of the input image. Image has different format and size. Here we convert all the images into one same single format and one fixed size.<br>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_44.JPG?raw=true' width='400'><br>\n",
    "彩色图层是3D的，所以这里 input_shape = (256,256,3)中，3代表3 channel - 彩色，1 channel - 黑白；两个256表示256x256 pixels。合起来，(256,256,3)意味着 256x256的彩色图层。使用 CPU 处理图层可以选择64x64(足够辨别)，用 GPU 处理图层可以选128x128。\n",
    "\n",
    "Convolution2D(64,3,3) means 使用64个3x3的 feature detectors。\n",
    "\n",
    "一般常规初始选择为32个 feature detectors 建立1st convolutional layer, 之后建其他的 convolutional layer 时逐步增加(64,128,256...) \n",
    "\n",
    "使用 rectifier function as activation function 来增加 non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 2:** Pooling\n",
    "\n",
    "MaxPooling2D 的 arguments:\n",
    "* pool_size: the size of the pooling table (通常使用2x2，不会丢失过多信息)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding 2nd Convolutional Layer and Pooling Layer**\n",
    "\n",
    "增加 CNN 的精准度\n",
    "\n",
    "Adding a new convolutional layer:\n",
    "* Do not need input_shape since input_shape is initial information before we create the layer from scratch.\n",
    "* Need the number of feature detectors (32), the dimensions of these feature detectors (3,3), an activation function\n",
    "\n",
    "Adding a new max pooling layer:\n",
    "* Only need pool size parameter\n",
    "\n",
    "注：常规方法，第二次还是使用和第一次数量相同的 feature detectors (32)。如果之后(第三次)还需要再添加 convolutional layer，则将 feature detector 数目翻倍(如下次64，再下次128...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only need input_shape if we don't have anything previously.\n",
    "classifier.add(Conv2D(32,(3,3),activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3:** Flattening\n",
    "\n",
    "问：为何不直接从原始图层 flattening 成 a huge vector？\n",
    "Each node of the huge vector will represent one pixel of the image independently of pixels that are around it. So we only get informations of the pixel itself and we won't get the informations of how this pixel especially connect to the other pixels around it.\n",
    "\n",
    "Each feature map corresponds to one specific feature of the image then each node in this huge vector that contains a high number will represent the information of a specific feature and specific detail of the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 4:** Full Connection\n",
    "\n",
    "Use Dense function to create the fully connection layer just like ANN.\n",
    "\n",
    "第一次建 full connection 时，units 表示第一层(input layers 的 output 数量，也就是需要多少个 hidden layers 作为第二层)。\n",
    "\n",
    "units = 第一层 numbers of hidden layers nodes = (input nodes + output nodes) / 2\n",
    "\n",
    "因为这次 input nodes 将会是 flatten 后 huge vector。所以我们将直接选取高数值 for units (如128 - power of 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(activation=\"relu\", units=128))\n",
    "# Add output layer\n",
    "# 2个或 2个以下输出用 sigmoid，超过2个则用softmax function.\n",
    "# 只需要 1个output (是狗或者猫)\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_45.JPG?raw=true' width='1000'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compiling the CNN\n",
    "\n",
    "More than 2 outcomes, we need use categorical_crossentropy as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the CNN to the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ImageDataGenerator](https://keras.io/preprocessing/image/)<br>\n",
    "Deep Learning 需要大量信息来学习。如 CNN 需要大量图片来训练，或者使用技巧 (ImageDataGenerator)。<br>\n",
    "\n",
    "ImageDataGenerator will create many batches of our images and each batch will apply some random transformations on a random selection of our image (like rotating, flipping, shifting, shearing). And we will get during the training is many more diverse images inside these batches and therefore a lot more material to train.\n",
    "\n",
    "Image augmentation is a technique that allows us to enrich the data sets for training without adding more images and prevent overfitting.<br>\n",
    "\n",
    "因为我们已经将训练图层和测试图层分类在不同文件夹里，所以将使用 '.flow_from_directory(diectory)'<br>\n",
    "The fit generator method will not only fit the CNN to the training set but also the test set at the same time.\n",
    "\n",
    "从 Keras Documentation 网页 Copy 以下 code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      " 663/8000 [=>............................] - ETA: 41:09 - loss: 0.6135 - acc: 0.6562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-371b9e1c3b01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m                         \u001b[1;31m# The number of images in the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                         \u001b[1;31m#validation_steps=800)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                         validation_steps=2000)\n\u001b[0m",
      "\u001b[1;32mC:\\Apps\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Apps\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Apps\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Apps\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Apps\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Apps\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Apps\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Apps\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 从 Keras Documentation 网页 Copy 以下 code:\n",
    "# (有所改动，原 code 被 comment)\n",
    " \n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#train_generator = train_datagen.flow_from_directory(\n",
    "training_set = train_datagen.flow_from_directory(# 'data/train',\n",
    "                                                 # from which directory\n",
    "                                                 'dataset/training_set',\n",
    "                                                 # the size of our images\n",
    "                                                 # target_size=(150, 150),\n",
    "                                                 # since we use 64x64 for our image\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=32,\n",
    "                                                 # it indicates the dependent variable\n",
    "                                                 # is binary or has more than 2 categories\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "#validation_generator = test_datagen.flow_from_directory(\n",
    "test_set = test_datagen.flow_from_directory(#'data/validation',\n",
    "                                            'dataset/test_set',\n",
    "                                            #target_size=(150, 150),\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n",
    "\n",
    "# Our model is called 'classifier'\n",
    "#model.fit_generator(#train_generator,\n",
    "classifier.fit_generator(#train_generator,\n",
    "                        # Here's the training set\n",
    "                        training_set,\n",
    "                        # The number of images in the training set\n",
    "                        # Because all the observation of the training set\n",
    "                        # pass through the CNN during each epoch.\n",
    "                        # Since we have 8000 images in the training set\n",
    "                        #steps_per_epoch=2000,\n",
    "                        steps_per_epoch=8000,\n",
    "                        # number of epochs we want to choose to train the CNN\n",
    "                        # 50 maybe too much, let's try 25\n",
    "                        #epochs=50,\n",
    "                        epochs=25,\n",
    "                        # Here's the test set\n",
    "                        #validation_data=validation_generator,\n",
    "                        validation_data=test_set,\n",
    "                        # The number of images in the test set\n",
    "                        #validation_steps=800)\n",
    "                        validation_steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Way to Improve the Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need make a deeper Deep Learning model (deeper CNN):\n",
    "* Add another Convolutional Layer (best solution)\n",
    "* Add another Full Connection Layer\n",
    "但是可以两个同时添加。\n",
    "\n",
    "新增的 Convolutional Layer 在之前的 Pooling Layer 之后。\n",
    "\n",
    "注：常规方法，第二次还是使用和第一次数量相同的 feature detectors (32)。如果之后(第三次)还需要再添加 convolutional layer，则将 feature detector 数目翻倍(如下次64，再下次128...)\n",
    "\n",
    "\n",
    "##### 更好的方法\n",
    "Adding more convolutional layers will help get an even better accuracy, but if we want to really get a better accuracy, we can choose a higher \"target_size\" in \n",
    "\n",
    "* train_datagen.flow_from_directory(... target_size=(64, 64), ...)\n",
    "\n",
    "* test_datagen.flow_from_directory(... target_size=(64, 64), ...)\n",
    "                                 \n",
    "For the images of the training and test set, so that we get more information of the pixel patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "207.534px",
    "left": "980.273px",
    "right": "20px",
    "top": "118px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
