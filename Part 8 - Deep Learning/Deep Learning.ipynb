{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning models can be used for a variety of complex tasks:\n",
    "* Artificial Neural Networks for Regression and Classification\n",
    "* Convolutional Neural Networks for Computer Vision\n",
    "* Recurrent Neural Networks for Time Series Analysis\n",
    "* Self Organizing Maps for Feature Extraction\n",
    "* Deep Boltzmann Machines for Recommendation Systems\n",
    "* Auto Encoders for Recommendation Systems\n",
    "\n",
    "We create an artificial structure called an artificial neural net (nodes or neurons). We will have some neurons for input values which are processed through all hidden layers just like in the human brain to have an output value. It is the Deep Learning.\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_1.JPG?raw=true' width='600'>\n",
    "\n",
    "##### 参考：\n",
    "[神经网络入门](http://www.ruanyifeng.com/blog/2017/07/neural-network.html#support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neuron is the basic building block of Artificial Neural Networks.<br>\n",
    "\n",
    "All input values can be considered as independent variable, and those will be added up or multiplied by some weight. In the case, they will be easier for neural network to process them if they are all about the same (Standardize or Normalize)\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_2.JPG?raw=true' width='500'>\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_3.JPG?raw=true' width='500'>\n",
    "If the output is categorical, then it will be several outputs values ($y_1, y_2 ... y_n$) because these will be dummy variables which will be representing the categories.\n",
    "\n",
    "The inputs are single observation (only in one row in the dataset) and the output is single observation as well. It means the input is for one row in dataset, then the output is for that the same exact row.\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_4.JPG?raw=true' width='500'>\n",
    "It's just all values in one row with different characteristics or attributes(columns) relating to that one observation(row), every single time, we are dealing with.\n",
    "\n",
    "All the Synapse get assigned weights. By adjusting the weights, the neural network decides in every single case (which signal is not important). It means we are training the artificial neural network by adjusting all of the weights in all of the synapse across the whole neural network.\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_5.JPG?raw=true' width='500'>\n",
    "\n",
    "Here is the thing happened in Neural node:\n",
    "STEP 1: To sum up all inputs with their weights\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_6.JPG?raw=true' width='500'>\n",
    "STEP 2: Apply the activation function which is assigned to the current neuron (or to the whole layer). \n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_7.JPG?raw=true' width='500'>\n",
    "STEP 3: The neuron will decide whether pass the signal or not based on the activation function applied in STEP 2.\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_8.JPG?raw=true' width='500'>\n",
    "Finally, those STEPs will be repeated throughout the whole neural network on and on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold Function (Yes or No type function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_9.JPG?raw=true' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function is useful in the final layer output. Especially when we are trying to predict probabilities. The probability of y is equal to 1.\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_10.JPG?raw=true' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectifier Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectifier function is one of the most popular functions in Artificial Neural Network.\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_11.JPG?raw=true' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperbolic Tangent (tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_12.JPG?raw=true' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which activation function we should use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the Dependent Variable (y) is binary (y = 0 or 1):\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_13.JPG?raw=true' width='500'>\n",
    "\n",
    "We also can apply the rectifier function in the hidden layers and the sigmoid function in the output layers\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_14.JPG?raw=true' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do Neural Networks Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个 Neural node (hidden layer) 根据自身的特点方面，可以 take 不同的 input values，以及不同的 activation function，最后合并产生结果。\n",
    "\n",
    "The whole hidden layers allows to increase the flexibility of the neural network. It allows the neural network to look for very specific things and then in combination.\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_15.JPG?raw=true' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do Neural Networks Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对结果的对比，让 Neural Networks 自己摸索学习。\n",
    "\n",
    "使用 cost function: $C = \\frac{(\\hat{y} - y)^2}{2}$，比较预测值和真实值的区别，并反馈给 Neural Networks。Neural Networks 将调解 weights 值，来缩小 cost function。\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_16.JPG?raw=true' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当 multiple rows inputs into the same ONE neural networks (not 8 neural network, just the same one)，产生相对应 each row 的$\\hat{y}$\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_17.JPG?raw=true' width='500'>\n",
    "随后比较相对应 each row 的真实值($y$)，生成$C= \\sum \\frac{(\\hat{y} - y)^2}{2}$。使用新生成的 Cost function (C) 来调节当前 neural network 中的 $w_1, w_2, w_3$ (the weights are the same for all of the rows, all the rows share the same weights)，最终使 Cost function 最小化。\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_18.JPG?raw=true' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 中所有 rows 全部输入同一 neural network 中，得到 Cost function。<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_20.JPG?raw=true' width='400'>\n",
    "\n",
    "通过对 Cost funtion 求导得到斜率，'-'为 downhill 则需要调整 weights，使$\\hat{y}$向右趋近取值； '+'为 uphill 则需要调整 weights，使$\\hat{y}$向左趋近取值。直至斜率 = 0 得到最小 Cost function (可能是 local minimum)\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_19.JPG?raw=true' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Gradient Descent:** Adjust weights after runing all of the rows in the same neural network. Then adjust weights and run the whole thing again (iteration) until minimize the Cost function.\n",
    "\n",
    "**Stochastic Gradient Descent:** Run one row at a time, then adjust weights (iteration) till minimize the Cost function. Then run next single row into the same neural network...\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_21.JPG?raw=true' width='400'>\n",
    "\n",
    "The stochastic gradient helps to avoid local minimums issue and it's faster than the batch gradient.\n",
    "\n",
    "**Mini Batch Gradient Descent:** combine both batch and stochastic gradient. Run 5, 10 or 100 rows (set by users) at a time, then adjust weights like stochastic gradient.\n",
    "\n",
    "##### 参考：\n",
    "[A Neural Network in 13 lines of Python (Part 2 - Gradient Descent)](https://iamtrask.github.io/2015/07/27/python-network-part2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information is entered into the input layer and then it's propagated forward to get the output values $\\hat{y}$. Then we compare $\\hat{y}$ to the actual values that we have in the training set. Then we calculate the errors (cost function).\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_22.JPG?raw=true' width='400'>\n",
    "Then feedback the errors (back propagate) through the network in the opposite direction and **it allows us to train the network by adjusting ALL the weights AT THE SAME TIME.**\n",
    "<img src='https://github.com/yunjcai/Machine-Learning-A-Z/blob/master/Part%208%20-%20Deep%20Learning/dl_23.JPG?raw=true' width='400'>\n",
    "The advantage of back propagation is the way algorithm to be structured. So you know which part of the error each weights in the neural network is repsonsible for.\n",
    "\n",
    "##### 参考：\n",
    "[Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap2.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the ANN with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 1:** Randomly initialise the weights to small numbers close to 0 (but not 0).<br>\n",
    "**STEP 2:** Input the first observation (first row) of the dataset in the input layer, each feature in one input node. (basically take the columns and put them into the input nodes)<br>\n",
    "**STEP 3:** Forward Propagation - from left to right, the neurons are activated in a way that the impact of each neuron's activation is limited by the weights (the weights determine how important each neurons activation is). Propagate the activations until getting the predicted result $y$<br>\n",
    "**STEP 4:** Compare the predicted result to the actual result. Measure the generated error (Cost function)<br>\n",
    "**STEP 5:** Back Propagation - from right to left, the error is back-propagated. Update the weights according to how much they are responsible for the error (because of the way back-propagated algorithm is structured). The learning rate decides by how much we update the weights.<br>\n",
    "**STEP 6:** Repeat STEPs 1-5 and update the weights after each observation (Reinforcement Learning, in our case, it is Stochastic Gradient Descent). Or: Repeat STEPs 1-5 but udpate the weights only after a batch of observation (Batch Learning).<br>\n",
    "**STEP 7:** When the whole training set passed through the ANN, that makes an epoch. Redo more epochs. (basically just keep doing again and again, to train better and better and adjust itself until the cost function is minimum.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
